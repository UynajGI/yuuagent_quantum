# scripts/build_clean_corpus.py
import ast
import json
import os
import re

# ================= é…ç½®è·¯å¾„ =================
PROJECT_ROOT = "/share/home/jiangyuan/yuuagent_quantum"
PATHS = {
    "source_code": os.path.join(PROJECT_ROOT, "tenpy", "tenpy"),
    "examples": os.path.join(PROJECT_ROOT, "tenpy", "examples"),
    "docs": os.path.join(PROJECT_ROOT, "tenpy", "doc"),
}
OUTPUT_FILE = os.path.join(PROJECT_ROOT, "src", "knowledge", "tenpy_corpus_clean.json")


# ================= 1. æºä»£ç è§£æå™¨ (ä¿®å¤ç‰ˆï¼šæ”¯æŒç±»ä½œç”¨åŸŸ) =================
class CodeVisitor(ast.NodeVisitor):
    def __init__(self, filename, relative_path):
        self.filename = filename
        self.relative_path = relative_path
        self.chunks = []
        # è®¡ç®—æ¨¡å—å: tenpy/tenpy/linalg/charges.py -> tenpy.tenpy.linalg.charges
        self.module_name = relative_path.replace("/", ".").replace(".py", "")
        # === å…³é”®ä¿®å¤ï¼šç±»ä½œç”¨åŸŸæ ˆ ===
        self.class_stack = []

    def visit_ClassDef(self, node):
        """æå–ç±»å®šä¹‰"""
        docstring = ast.get_docstring(node) or ""
        source_segment = ast.get_source_segment(self.source_code, node)

        # ç±»å ID: module.ClassName
        full_class_name = f"{self.module_name}.{node.name}"

        self.chunks.append(
            {
                "type": "api_class",
                "name": full_class_name,
                "file": self.relative_path,
                "content": source_segment,
                "summary": docstring.split("\n\n")[0]
                if docstring
                else "No description.",
                "metadata": {
                    "bases": [b.id for b in node.bases if isinstance(b, ast.Name)],
                    "methods": [
                        n.name for n in node.body if isinstance(n, ast.FunctionDef)
                    ],
                },
            }
        )

        # === å…³é”®ä¿®å¤ï¼šå…¥æ ˆ -> è®¿é—®å­èŠ‚ç‚¹ -> å‡ºæ ˆ ===
        self.class_stack.append(node.name)
        self.generic_visit(node)  # ç»§ç»­éå†ç±»å†…éƒ¨çš„æ–¹æ³•
        self.class_stack.pop()

    def visit_FunctionDef(self, node):
        """æå–å‡½æ•°å®šä¹‰ (åŒ…æ‹¬ç±»æ–¹æ³•å’Œç‹¬ç«‹å‡½æ•°)"""
        # å¿½ç•¥ç§æœ‰æ–¹æ³•ï¼Œä½†ä¿ç•™ __init__ å’Œ __call__
        if node.name.startswith("_") and node.name not in ["__init__", "__call__"]:
            return

        docstring = ast.get_docstring(node) or ""
        source_segment = ast.get_source_segment(self.source_code, node)

        # === å…³é”®ä¿®å¤ï¼šæ ¹æ®æ ˆåˆ¤æ–­æ˜¯æ–¹æ³•è¿˜æ˜¯å‡½æ•° ===
        if self.class_stack:
            # è¿™æ˜¯ä¸€ä¸ªç±»æ–¹æ³•: module.ClassName.method_name
            parent_class = self.class_stack[-1]
            unique_name = f"{self.module_name}.{parent_class}.{node.name}"
            func_type = "api_method"
        else:
            # è¿™æ˜¯ä¸€ä¸ªé¡¶å±‚å‡½æ•°: module.function_name
            unique_name = f"{self.module_name}.{node.name}"
            func_type = "api_function"

        self.chunks.append(
            {
                "type": func_type,
                "name": unique_name,
                "file": self.relative_path,
                "content": source_segment,
                "summary": docstring.split("\n\n")[0] if docstring else "",
                "metadata": {
                    "args": [a.arg for a in node.args.args],
                    "parent_class": self.class_stack[-1] if self.class_stack else None,
                },
            }
        )
        # å‡½æ•°å†…éƒ¨å®šä¹‰çš„å‡½æ•°ä¸€èˆ¬ä¸éœ€è¦æå–ï¼Œä¸å†é€’å½’

    def parse(self):
        with open(self.filename, "r", encoding="utf-8") as f:
            self.source_code = f.read()

        try:
            tree = ast.parse(self.source_code)
            self.visit(tree)
        except Exception as e:
            print(f"âš ï¸ AST Parse Error in {self.filename}: {e}")
        return self.chunks


# ================= 2. æ–‡æ¡£æ¸…æ´—å™¨ (ä¿æŒä¸å˜) =================
def clean_rst(text: str) -> str:
    text = re.sub(r"\.\. \w+::.*", "", text)
    text = re.sub(r":\w+ .*?:", "", text)
    text = re.sub(r":\w+:`(.*?)`", r"\1", text)
    text = re.sub(r"`(.*?)\s<.*?>`_", r"\1", text)
    lines = [line.strip() for line in text.split("\n")]
    clean_lines = [l for l in lines if l]
    return "\n".join(clean_lines)


def process_docs(doc_root):
    chunks = []
    for root, _, files in os.walk(doc_root):
        for file in files:
            if not file.endswith(".rst"):
                continue

            full_path = os.path.join(root, file)
            rel_path = os.path.relpath(full_path, doc_root)

            with open(full_path, "r", encoding="utf-8") as f:
                raw_content = f.read()

            clean_content = clean_rst(raw_content)

            if len(clean_content) > 100:
                chunks.append(
                    {
                        "type": "doc_tutorial",
                        "name": f"doc_{rel_path.replace('/', '_').replace('.rst', '')}",
                        "file": rel_path,
                        "content": clean_content,
                        "summary": clean_content[:200],
                        "metadata": {"format": "rst_cleaned"},
                    }
                )
    return chunks


# ================= 3. ç¤ºä¾‹å¤„ç† (ä¿æŒä¸å˜) =================
def process_examples(example_root):
    chunks = []
    for root, _, files in os.walk(example_root):
        for file in files:
            if not file.endswith(".py"):
                continue

            full_path = os.path.join(root, file)
            rel_path = os.path.relpath(full_path, example_root)

            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read()

            chunks.append(
                {
                    "type": "example_script",
                    "name": f"example_{file}",
                    "file": rel_path,
                    "content": f"### Example Script: {file} ###\n{content}",
                    "summary": f"Full executable example: {file}",
                    "metadata": {"executable": True},
                }
            )
    return chunks


# ================= ä¸»æµç¨‹ =================
def main():
    all_knowledge = []
    seen_ids = set()

    print("ğŸš€ Starting Knowledge ETL (Scope-Aware Version)...")

    # 1. Process Source Code
    print("Parsing Source Code (AST)...")
    for root, _, files in os.walk(PATHS["source_code"]):
        for file in files:
            if file.endswith(".py"):
                full_path = os.path.join(root, file)
                rel_path = os.path.relpath(full_path, PROJECT_ROOT)
                visitor = CodeVisitor(full_path, rel_path)
                chunks = visitor.parse()
                all_knowledge.extend(chunks)

    # 2. Process Docs
    print("Cleaning Documentation (RST)...")
    all_knowledge.extend(process_docs(PATHS["docs"]))

    # 3. Process Examples
    print("Loading Examples...")
    all_knowledge.extend(process_examples(PATHS["examples"]))

    # === 4. å»é‡å¤„ç† (Final Deduplication) ===
    unique_knowledge = []
    for item in all_knowledge:
        if item["name"] in seen_ids:
            # å¦‚æœçœŸçš„è¿˜æœ‰é‡å¤ (æ¯”å¦‚ if/else å®šä¹‰äº†ä¸¤æ¬¡åŒåå‡½æ•°)ï¼Œè·³è¿‡æˆ–åŠ åç¼€
            continue
        seen_ids.add(item["name"])
        unique_knowledge.append(item)

    print(f"âœ… Extracted {len(unique_knowledge)} unique knowledge chunks.")

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(unique_knowledge, f, indent=2, ensure_ascii=False)

    print(f"ğŸ’¾ Corpus saved to: {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
